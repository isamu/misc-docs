# å®Ÿè·µä¾‹ã¨ã‚³ãƒ¼ãƒ‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

## æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€ã“ã‚Œã¾ã§ã®å†…å®¹ã‚’çµ±åˆã—ãŸ**å®Ÿéš›ã«å‹•ä½œã™ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹**ã‚’æä¾›ã—ã¾ã™ã€‚

å„ä¾‹ã¯ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ã—ã¦ä½¿ãˆã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚

---

## ğŸ¯ ä¾‹1: æœ€å°é™ã®Claudeé¢¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ã§ã™ã€‚

### minimal_agent.py

```python
"""
æœ€å°é™ã®Claudeé¢¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ä¾å­˜é–¢ä¿‚:
pip install langgraph langchain-anthropic
"""

from typing import TypedDict, Annotated
from langgraph.graph import StateGraph, END, add_messages
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, SystemMessage
import os

# === Stateå®šç¾© ===

class MinimalState(TypedDict):
    messages: Annotated[list, add_messages]
    goal: str
    status: str  # 'working' | 'done'
    iteration: int

# === LLMåˆæœŸåŒ– ===

llm = ChatAnthropic(
    model="claude-sonnet-4-5-20251101",
    api_key=os.getenv("ANTHROPIC_API_KEY"),
    temperature=0
)

SYSTEM_PROMPT = """
ã‚ãªãŸã¯æœ‰ç›Šã§èª å®Ÿãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

åŸå‰‡:
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç›®æ¨™é”æˆã‚’æ”¯æ´ã™ã‚‹
2. ä¸ç¢ºå®Ÿãªæƒ…å ±ã¯æ˜ç¤ºã™ã‚‹
3. æœ‰å®³ãªå‡ºåŠ›ã‚’é¿ã‘ã‚‹

ã‚¿ã‚¹ã‚¯ã‚’1ã‚¹ãƒ†ãƒƒãƒ—ãšã¤å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
å„ã‚¹ãƒ†ãƒƒãƒ—ã®å¾Œã€ç›®æ¨™ãŒé”æˆã•ã‚ŒãŸã‹åˆ¤æ–­ã—ã¦ãã ã•ã„ã€‚
"""

# === ãƒãƒ¼ãƒ‰å®šç¾© ===

def think_node(state: MinimalState) -> MinimalState:
    """æ€è€ƒãƒãƒ¼ãƒ‰"""
    print(f"\n[Iteration {state['iteration']}] Thinking...")

    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        *state["messages"],
        HumanMessage(content=f"""
<goal>{state['goal']}</goal>

æ¬¡ã«ä½•ã‚’ã™ã¹ãã‹è€ƒãˆã¦ãã ã•ã„ã€‚
ç›®æ¨™ãŒé”æˆã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ŒDONEã€ã¨æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚

å›ç­”å½¢å¼:
<next_action>
è¡Œã†ã¹ãã“ã¨ã€ã¾ãŸã¯ã€ŒDONEã€
</next_action>
<reasoning>
ç†ç”±
</reasoning>
""")
    ]

    response = llm.invoke(messages)

    # DONEãƒã‚§ãƒƒã‚¯
    if "DONE" in response.content:
        return {
            **state,
            "status": "done",
            "messages": state["messages"] + [response]
        }

    return {
        **state,
        "iteration": state["iteration"] + 1,
        "messages": state["messages"] + [response]
    }

def should_continue(state: MinimalState) -> str:
    """ç¶™ç¶šåˆ¤å®š"""
    if state["status"] == "done":
        return "end"

    if state["iteration"] >= 10:
        print("Max iterations reached")
        return "end"

    return "continue"

# === ã‚°ãƒ©ãƒ•æ§‹ç¯‰ ===

workflow = StateGraph(MinimalState)

workflow.add_node("think", think_node)

workflow.set_entry_point("think")

workflow.add_conditional_edges(
    "think",
    should_continue,
    {
        "continue": "think",
        "end": END
    }
)

app = workflow.compile()

# === å®Ÿè¡Œ ===

def run_agent(goal: str):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ"""
    initial_state = {
        "messages": [],
        "goal": goal,
        "status": "working",
        "iteration": 0
    }

    print(f"ğŸ¯ Goal: {goal}\n")
    print("=" * 60)

    result = app.invoke(initial_state)

    print("\n" + "=" * 60)
    print(f"âœ… Completed in {result['iteration']} iterations")
    print("\nFinal messages:")

    for msg in result["messages"]:
        role = msg.__class__.__name__
        content = msg.content[:200] + "..." if len(msg.content) > 200 else msg.content
        print(f"\n[{role}]\n{content}")

if __name__ == "__main__":
    run_agent("Calculate 15 * 23 and explain the process")
```

### å®Ÿè¡Œ

```bash
export ANTHROPIC_API_KEY="your-key-here"
python minimal_agent.py
```

---

## ğŸ”§ ä¾‹2: ãƒ„ãƒ¼ãƒ«çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ãˆã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

### tool_agent.py

```python
"""
ãƒ„ãƒ¼ãƒ«çµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

è¿½åŠ ã®ä¾å­˜é–¢ä¿‚:
pip install requests beautifulsoup4
"""

from typing import TypedDict, Annotated, Literal
from langgraph.graph import StateGraph, END, add_messages
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
import requests
from bs4 import BeautifulSoup
import json

# === ãƒ„ãƒ¼ãƒ«å®šç¾© ===

@tool
def web_search(query: str) -> str:
    """
    Webæ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
    """
    # DuckDuckGo Instant Answer APIï¼ˆç„¡æ–™ï¼‰
    url = "https://api.duckduckgo.com/"
    params = {"q": query, "format": "json"}

    try:
        response = requests.get(url, params=params, timeout=10)
        data = response.json()

        # çµæœã‚’æ•´å½¢
        results = []

        if data.get("AbstractText"):
            results.append(f"Summary: {data['AbstractText']}")

        if data.get("RelatedTopics"):
            results.append("\nRelated:")
            for topic in data["RelatedTopics"][:3]:
                if "Text" in topic:
                    results.append(f"- {topic['Text']}")

        return "\n".join(results) if results else "No results found"

    except Exception as e:
        return f"Search failed: {str(e)}"

@tool
def fetch_url(url: str) -> str:
    """
    URLã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã—ã¾ã™ã€‚

    Args:
        url: å–å¾—ã™ã‚‹URL
    """
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
        text = soup.get_text(separator='\n', strip=True)

        # æœ€åˆã®2000æ–‡å­—ã®ã¿
        return text[:2000]

    except Exception as e:
        return f"Failed to fetch URL: {str(e)}"

@tool
def calculate(expression: str) -> str:
    """
    æ•°å¼ã‚’è¨ˆç®—ã—ã¾ã™ã€‚

    Args:
        expression: è¨ˆç®—å¼ï¼ˆä¾‹: "2 + 2"ï¼‰
    """
    try:
        # å®‰å…¨ãªè©•ä¾¡
        result = eval(expression, {"__builtins__": {}}, {})
        return str(result)
    except Exception as e:
        return f"Calculation failed: {str(e)}"

# ãƒ„ãƒ¼ãƒ«ãƒªã‚¹ãƒˆ
tools = [web_search, fetch_url, calculate]

# === Stateå®šç¾© ===

class ToolAgentState(TypedDict):
    messages: Annotated[list, add_messages]
    goal: str
    status: Literal['planning', 'acting', 'done']

# === LLMåˆæœŸåŒ–ï¼ˆãƒ„ãƒ¼ãƒ«ãƒã‚¤ãƒ³ãƒ‰ï¼‰ ===

llm = ChatAnthropic(
    model="claude-sonnet-4-5-20251101",
    temperature=0
).bind_tools(tools)

SYSTEM_PROMPT = """
ã‚ãªãŸã¯æœ‰ç›Šãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«:
- web_search: Webæ¤œç´¢
- fetch_url: URLã®å†…å®¹å–å¾—
- calculate: è¨ˆç®—

åŸå‰‡:
1. ã¾ãšå†…éƒ¨çŸ¥è­˜ã§å›ç­”ã§ãã‚‹ã‹æ¤œè¨
2. å¿…è¦ãªå ´åˆã®ã¿ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨
3. ãƒ„ãƒ¼ãƒ«çµæœã‚’æ¤œè¨¼ã—ã¦ã‹ã‚‰å›ç­”
"""

# === ãƒãƒ¼ãƒ‰å®šç¾© ===

def agent_node(state: ToolAgentState) -> ToolAgentState:
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ‰"""
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        *state["messages"]
    ]

    response = llm.invoke(messages)

    return {
        **state,
        "messages": state["messages"] + [response]
    }

def tool_node(state: ToolAgentState) -> ToolAgentState:
    """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œãƒãƒ¼ãƒ‰"""
    last_message = state["messages"][-1]

    tool_calls = last_message.tool_calls

    tool_messages = []

    for tool_call in tool_calls:
        tool_name = tool_call["name"]
        tool_args = tool_call["args"]

        print(f"\nğŸ”§ Calling tool: {tool_name}")
        print(f"   Args: {tool_args}")

        # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ
        selected_tool = {t.name: t for t in tools}[tool_name]
        result = selected_tool.invoke(tool_args)

        print(f"   Result: {result[:100]}...")

        tool_messages.append(
            ToolMessage(
                content=str(result),
                tool_call_id=tool_call["id"]
            )
        )

    return {
        **state,
        "messages": state["messages"] + tool_messages
    }

def should_continue(state: ToolAgentState) -> str:
    """ç¶™ç¶šåˆ¤å®š"""
    last_message = state["messages"][-1]

    # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚ã‚Œã°å®Ÿè¡Œ
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "tools"

    # ãªã‘ã‚Œã°çµ‚äº†
    return "end"

# === ã‚°ãƒ©ãƒ•æ§‹ç¯‰ ===

workflow = StateGraph(ToolAgentState)

workflow.add_node("agent", agent_node)
workflow.add_node("tools", tool_node)

workflow.set_entry_point("agent")

workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "tools": "tools",
        "end": END
    }
)

workflow.add_edge("tools", "agent")

app = workflow.compile()

# === å®Ÿè¡Œ ===

def run_tool_agent(goal: str):
    """ãƒ„ãƒ¼ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ"""
    initial_state = {
        "messages": [HumanMessage(content=goal)],
        "goal": goal,
        "status": "planning"
    }

    print(f"ğŸ¯ Goal: {goal}\n")
    print("=" * 60)

    result = app.invoke(initial_state)

    print("\n" + "=" * 60)
    print("âœ… Completed\n")

    # æœ€çµ‚å›ç­”ã‚’æŠ½å‡º
    for msg in reversed(result["messages"]):
        if hasattr(msg, 'content') and msg.content and not hasattr(msg, 'tool_calls'):
            print(f"Answer:\n{msg.content}")
            break

if __name__ == "__main__":
    # ä¾‹1: è¨ˆç®—
    run_tool_agent("What is 456 * 789?")

    print("\n\n")

    # ä¾‹2: Webæ¤œç´¢
    run_tool_agent("What is LangGraph?")
```

---

## ğŸ“š ä¾‹3: RAGçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã‚’ä½¿ã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

### rag_agent.py

```python
"""
RAGçµ±åˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

è¿½åŠ ã®ä¾å­˜é–¢ä¿‚:
pip install chromadb sentence-transformers
"""

from typing import TypedDict, Annotated
from langgraph.graph import StateGraph, END, add_messages
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, SystemMessage
import chromadb
from chromadb.utils import embedding_functions

# === RAGã‚·ã‚¹ãƒ†ãƒ  ===

class SimpleRAG:
    def __init__(self, collection_name: str = "knowledge"):
        # ChromaDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        self.client = chromadb.Client()

        # åŸ‹ã‚è¾¼ã¿é–¢æ•°
        self.embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2"
        )

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
        self.collection = self.client.create_collection(
            name=collection_name,
            embedding_function=self.embedding_fn,
            get_or_create=True
        )

    def add_documents(self, documents: list[dict]):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ """
        self.collection.add(
            ids=[doc["id"] for doc in documents],
            documents=[doc["text"] for doc in documents],
            metadatas=[doc.get("metadata", {}) for doc in documents]
        )

        print(f"âœ… Added {len(documents)} documents")

    def search(self, query: str, n_results: int = 3) -> list[dict]:
        """æ¤œç´¢"""
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results
        )

        return [
            {
                "text": doc,
                "metadata": meta
            }
            for doc, meta in zip(
                results["documents"][0],
                results["metadatas"][0]
            )
        ]

# === Stateå®šç¾© ===

class RAGAgentState(TypedDict):
    messages: Annotated[list, add_messages]
    query: str
    retrieved_docs: list[dict]
    status: str

# === ãƒãƒ¼ãƒ‰å®šç¾© ===

def retrieve_node(state: RAGAgentState, rag: SimpleRAG) -> RAGAgentState:
    """æ¤œç´¢ãƒãƒ¼ãƒ‰"""
    print("\nğŸ” Retrieving documents...")

    docs = rag.search(state["query"], n_results=3)

    print(f"   Found {len(docs)} relevant documents")

    return {
        **state,
        "retrieved_docs": docs
    }

def generate_node(state: RAGAgentState, llm) -> RAGAgentState:
    """ç”Ÿæˆãƒãƒ¼ãƒ‰"""
    print("\nğŸ¤– Generating answer...")

    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
    context = "\n\n".join([
        f"<document>\n{doc['text']}\n</document>"
        for doc in state["retrieved_docs"]
    ])

    prompt = f"""
<context>
{context}
</context>

<query>
{state['query']}
</query>

ä¸Šè¨˜ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦ã€è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æƒ…å ±ãŒãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚
"""

    messages = [
        SystemMessage(content="ã‚ãªãŸã¯æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å›ç­”ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
        HumanMessage(content=prompt)
    ]

    response = llm.invoke(messages)

    return {
        **state,
        "messages": state["messages"] + [response],
        "status": "done"
    }

# === ã‚°ãƒ©ãƒ•æ§‹ç¯‰ ===

def create_rag_agent(rag: SimpleRAG):
    """RAGã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ"""
    llm = ChatAnthropic(model="claude-sonnet-4-5-20251101", temperature=0)

    workflow = StateGraph(RAGAgentState)

    workflow.add_node("retrieve", lambda s: retrieve_node(s, rag))
    workflow.add_node("generate", lambda s: generate_node(s, llm))

    workflow.set_entry_point("retrieve")
    workflow.add_edge("retrieve", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()

# === å®Ÿè¡Œ ===

def main():
    # RAGã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    rag = SimpleRAG()

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
    sample_docs = [
        {
            "id": "doc1",
            "text": "LangGraphã¯ã€LangChainãƒãƒ¼ãƒ ãŒé–‹ç™ºã—ãŸã‚¹ãƒ†ãƒ¼ãƒˆãƒ•ãƒ«ãªãƒãƒ«ãƒã‚¢ã‚¯ã‚¿ãƒ¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®å®Ÿè¡Œãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚",
            "metadata": {"source": "docs", "topic": "langgraph"}
        },
        {
            "id": "doc2",
            "text": "Model Context Protocol (MCP)ã¯ã€AnthropicãŒé–‹ç™ºã—ãŸLLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’æ¥ç¶šã™ã‚‹ãŸã‚ã®æ¨™æº–ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚",
            "metadata": {"source": "docs", "topic": "mcp"}
        },
        {
            "id": "doc3",
            "text": "Claude 3.5 Sonnetã¯ã€Anthropicã®æœ€æ–°AIãƒ¢ãƒ‡ãƒ«ã§ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€æ¨è«–ã€è¦–è¦šå‡¦ç†ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚200Kãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æŒã¡ã¾ã™ã€‚",
            "metadata": {"source": "docs", "topic": "claude"}
        }
    ]

    rag.add_documents(sample_docs)

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
    app = create_rag_agent(rag)

    # è³ªå•
    queries = [
        "LangGraphã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "MCPã®ç›®çš„ã¯ï¼Ÿ",
        "Claudeã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã¯ï¼Ÿ"
    ]

    for query in queries:
        print(f"\n{'='*60}")
        print(f"â“ Query: {query}")
        print('='*60)

        result = app.invoke({
            "messages": [],
            "query": query,
            "retrieved_docs": [],
            "status": "searching"
        })

        # å›ç­”ã‚’è¡¨ç¤º
        answer = result["messages"][-1].content
        print(f"\nğŸ’¡ Answer:\n{answer}")

if __name__ == "__main__":
    main()
```

---

## ğŸ¬ ä¾‹4: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ç”»åƒãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ‰±ã†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚

### multimodal_agent.py

```python
"""
ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

è¿½åŠ ã®ä¾å­˜é–¢ä¿‚:
pip install anthropic pillow
"""

import anthropic
import base64
from pathlib import Path
from typing import TypedDict
import json

class MultimodalAgent:
    def __init__(self, api_key: str):
        self.client = anthropic.Anthropic(api_key=api_key)

    def encode_image(self, image_path: str) -> dict:
        """ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰"""
        with open(image_path, "rb") as f:
            image_data = base64.standard_b64encode(f.read()).decode("utf-8")

        # MIMEã‚¿ã‚¤ãƒ—åˆ¤å®š
        suffix = Path(image_path).suffix.lower()
        mime_types = {
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".png": "image/png",
            ".gif": "image/gif",
            ".webp": "image/webp"
        }

        return {
            "type": "image",
            "source": {
                "type": "base64",
                "media_type": mime_types.get(suffix, "image/jpeg"),
                "data": image_data
            }
        }

    def analyze_image(self, image_path: str, query: str) -> str:
        """ç”»åƒã‚’åˆ†æ"""
        print(f"\nğŸ–¼ï¸  Analyzing image: {image_path}")
        print(f"   Query: {query}")

        image_content = self.encode_image(image_path)

        message = self.client.messages.create(
            model="claude-sonnet-4-5-20251101",
            max_tokens=1024,
            messages=[
                {
                    "role": "user",
                    "content": [
                        image_content,
                        {
                            "type": "text",
                            "text": query
                        }
                    ]
                }
            ]
        )

        return message.content[0].text

    def analyze_document_with_images(
        self,
        images: list[str],
        query: str
    ) -> str:
        """è¤‡æ•°ç”»åƒã‚’å«ã‚€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’åˆ†æ"""
        print(f"\nğŸ“„ Analyzing document with {len(images)} images")

        content = []

        # ã™ã¹ã¦ã®ç”»åƒã‚’è¿½åŠ 
        for img_path in images:
            content.append(self.encode_image(img_path))

        # ã‚¯ã‚¨ãƒªã‚’è¿½åŠ 
        content.append({
            "type": "text",
            "text": f"""
ä»¥ä¸‹ã®ç”»åƒã¯1ã¤ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æŠ½å‡ºã•ã‚ŒãŸã‚‚ã®ã§ã™ã€‚

è³ªå•: {query}

ã™ã¹ã¦ã®ç”»åƒã‚’å‚ç…§ã—ã¦ã€åŒ…æ‹¬çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
        })

        message = self.client.messages.create(
            model="claude-sonnet-4-5-20251101",
            max_tokens=2048,
            messages=[
                {
                    "role": "user",
                    "content": content
                }
            ]
        )

        return message.content[0].text

    def compare_images(self, image1: str, image2: str) -> str:
        """2ã¤ã®ç”»åƒã‚’æ¯”è¼ƒ"""
        print(f"\nğŸ” Comparing images:")
        print(f"   Image 1: {image1}")
        print(f"   Image 2: {image2}")

        content = [
            self.encode_image(image1),
            self.encode_image(image2),
            {
                "type": "text",
                "text": "ã“ã‚Œã‚‰2ã¤ã®ç”»åƒã‚’æ¯”è¼ƒã—ã¦ã€é•ã„ã¨å…±é€šç‚¹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
            }
        ]

        message = self.client.messages.create(
            model="claude-sonnet-4-5-20251101",
            max_tokens=1024,
            messages=[
                {
                    "role": "user",
                    "content": content
                }
            ]
        )

        return message.content[0].text

# === ä½¿ç”¨ä¾‹ ===

def main():
    import os

    agent = MultimodalAgent(api_key=os.getenv("ANTHROPIC_API_KEY"))

    # ä¾‹1: å˜ä¸€ç”»åƒåˆ†æ
    # result = agent.analyze_image(
    #     "path/to/image.jpg",
    #     "ã“ã®ç”»åƒã«ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ"
    # )
    # print(f"\nå›ç­”:\n{result}")

    # ä¾‹2: è¤‡æ•°ç”»åƒåˆ†æ
    # result = agent.analyze_document_with_images(
    #     ["page1.jpg", "page2.jpg", "page3.jpg"],
    #     "ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ"
    # )
    # print(f"\nå›ç­”:\n{result}")

    # ä¾‹3: ç”»åƒæ¯”è¼ƒ
    # result = agent.compare_images(
    #     "before.jpg",
    #     "after.jpg"
    # )
    # print(f"\næ¯”è¼ƒçµæœ:\n{result}")

    print("âœ… Multimodal agent ready")
    print("   Uncomment examples in main() to test")

if __name__ == "__main__":
    main()
```

---

## ğŸ§ª ä¾‹5: ãƒ‡ãƒãƒƒã‚°ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚

### debug_tools.py

```python
"""
ãƒ‡ãƒãƒƒã‚°ã¨ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ„ãƒ¼ãƒ«
"""

import time
import json
from typing import Any
from functools import wraps

class AgentMonitor:
    def __init__(self):
        self.logs = []
        self.start_time = None

    def start(self):
        """ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°é–‹å§‹"""
        self.start_time = time.time()
        self.logs = []

    def log(self, event_type: str, data: Any):
        """ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãƒ­ã‚°"""
        self.logs.append({
            "timestamp": time.time() - self.start_time,
            "type": event_type,
            "data": data
        })

    def print_summary(self):
        """ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        print("\n" + "="*60)
        print("ğŸ“Š Agent Execution Summary")
        print("="*60)

        # å®Ÿè¡Œæ™‚é–“
        total_time = self.logs[-1]["timestamp"] if self.logs else 0
        print(f"\nâ±ï¸  Total time: {total_time:.2f}s")

        # ã‚¤ãƒ™ãƒ³ãƒˆæ•°
        event_counts = {}
        for log in self.logs:
            event_type = log["type"]
            event_counts[event_type] = event_counts.get(event_type, 0) + 1

        print(f"\nğŸ“ˆ Events:")
        for event_type, count in event_counts.items():
            print(f"   {event_type}: {count}")

        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
        total_tokens = sum(
            log["data"].get("tokens", 0)
            for log in self.logs
            if isinstance(log["data"], dict)
        )

        if total_tokens > 0:
            print(f"\nğŸ« Total tokens: {total_tokens:,}")

    def save_logs(self, filepath: str):
        """ãƒ­ã‚°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        with open(filepath, 'w') as f:
            json.dump(self.logs, f, indent=2)

        print(f"ğŸ’¾ Logs saved to {filepath}")

# ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿

def monitor_node(monitor: AgentMonitor):
    """ãƒãƒ¼ãƒ‰å®Ÿè¡Œã‚’ãƒ¢ãƒ‹ã‚¿ãƒ¼"""
    def decorator(func):
        @wraps(func)
        def wrapper(state):
            node_name = func.__name__

            # é–‹å§‹ãƒ­ã‚°
            monitor.log("node_start", {
                "node": node_name,
                "state_keys": list(state.keys())
            })

            start = time.time()

            # å®Ÿè¡Œ
            result = func(state)

            # çµ‚äº†ãƒ­ã‚°
            duration = time.time() - start
            monitor.log("node_end", {
                "node": node_name,
                "duration": duration
            })

            print(f"   [{node_name}] {duration:.2f}s")

            return result

        return wrapper
    return decorator

# === ä½¿ç”¨ä¾‹ ===

monitor = AgentMonitor()

@monitor_node(monitor)
def example_node(state):
    """ä¾‹ãƒãƒ¼ãƒ‰"""
    time.sleep(0.5)  # å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    return state

# å®Ÿè¡Œ
monitor.start()

state = {"test": "data"}

for i in range(3):
    state = example_node(state)

monitor.print_summary()
monitor.save_logs("agent_logs.json")
```

---

## ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

è‡ªåˆ†å°‚ç”¨ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œã‚‹éš›ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ã™ã€‚

### custom_agent_template.py

```python
"""
ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

ã“ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã€ç‹¬è‡ªã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""

from typing import TypedDict, Annotated, Literal
from langgraph.graph import StateGraph, END, add_messages
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, SystemMessage

# ===========================
# 1. Stateå®šç¾©
# ===========================

class CustomState(TypedDict):
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŠ¶æ…‹ã‚’å®šç¾©

    ã“ã“ã«å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„
    """
    messages: Annotated[list, add_messages]

    # ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆä¾‹ï¼‰
    goal: str
    current_step: int
    max_steps: int
    status: Literal['working', 'done', 'failed']

    # ä»¥ä¸‹ã«è¿½åŠ ...

# ===========================
# 2. ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# ===========================

SYSTEM_PROMPT = """
ã‚ãªãŸã®å½¹å‰²ã¨ãƒ«ãƒ¼ãƒ«ã‚’ã“ã“ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

ä¾‹:
ã‚ãªãŸã¯ã€‡ã€‡ã‚’æ”¯æ´ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚

åŸå‰‡:
1. ...
2. ...
3. ...
"""

# ===========================
# 3. LLMåˆæœŸåŒ–
# ===========================

llm = ChatAnthropic(
    model="claude-sonnet-4-5-20251101",  # ã¾ãŸã¯ä»–ã®ãƒ¢ãƒ‡ãƒ«
    temperature=0,  # å¿…è¦ã«å¿œã˜ã¦èª¿æ•´
    max_tokens=4096
)

# ===========================
# 4. ãƒãƒ¼ãƒ‰å®šç¾©
# ===========================

def my_node_1(state: CustomState) -> CustomState:
    """
    æœ€åˆã®ãƒãƒ¼ãƒ‰

    ã“ã“ã§ä½•ã‚’ã™ã‚‹ã‹èª¬æ˜ã—ã¦ãã ã•ã„
    """
    print(f"\n[Node 1] Step {state['current_step']}")

    # å‡¦ç†ã‚’ã“ã“ã«å®Ÿè£…
    # ...

    return {
        **state,
        "current_step": state["current_step"] + 1
    }

def my_node_2(state: CustomState) -> CustomState:
    """
    2ç•ªç›®ã®ãƒãƒ¼ãƒ‰
    """
    print(f"\n[Node 2] Processing...")

    # LLMå‘¼ã³å‡ºã—ã®ä¾‹
    messages = [
        SystemMessage(content=SYSTEM_PROMPT),
        *state["messages"],
        HumanMessage(content="...")  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
    ]

    response = llm.invoke(messages)

    return {
        **state,
        "messages": state["messages"] + [response]
    }

# ===========================
# 5. ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°é–¢æ•°
# ===========================

def should_continue(state: CustomState) -> str:
    """
    æ¬¡ã«ã©ã®ãƒãƒ¼ãƒ‰ã«é€²ã‚€ã‹æ±ºå®š
    """
    if state["status"] == "done":
        return "end"

    if state["current_step"] >= state["max_steps"]:
        return "end"

    # æ¡ä»¶ã«å¿œã˜ã¦ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    # ...

    return "continue"

# ===========================
# 6. ã‚°ãƒ©ãƒ•æ§‹ç¯‰
# ===========================

workflow = StateGraph(CustomState)

# ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 
workflow.add_node("node1", my_node_1)
workflow.add_node("node2", my_node_2)
# ... ä»–ã®ãƒãƒ¼ãƒ‰ã‚’è¿½åŠ 

# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
workflow.set_entry_point("node1")

# ã‚¨ãƒƒã‚¸ã‚’å®šç¾©
workflow.add_edge("node1", "node2")

# æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸
workflow.add_conditional_edges(
    "node2",
    should_continue,
    {
        "continue": "node1",  # ãƒ«ãƒ¼ãƒ—
        "end": END
    }
)

# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
app = workflow.compile()

# ===========================
# 7. å®Ÿè¡Œé–¢æ•°
# ===========================

def run(goal: str, max_steps: int = 10):
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ

    Args:
        goal: é”æˆã—ãŸã„ç›®æ¨™
        max_steps: æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°
    """
    initial_state: CustomState = {
        "messages": [],
        "goal": goal,
        "current_step": 0,
        "max_steps": max_steps,
        "status": "working"
    }

    print(f"ğŸš€ Starting agent")
    print(f"   Goal: {goal}")
    print(f"   Max steps: {max_steps}")
    print("="*60)

    result = app.invoke(initial_state)

    print("\n" + "="*60)
    print(f"âœ… Completed")
    print(f"   Steps: {result['current_step']}")
    print(f"   Status: {result['status']}")

    return result

# ===========================
# 8. ãƒ¡ã‚¤ãƒ³
# ===========================

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    result = run(
        goal="Your goal here",
        max_steps=5
    )
```

---

## ğŸ“š å‚è€ƒè³‡æ–™

### ã™ã¹ã¦ã®ä¾‹ã§ä½¿ç”¨ã—ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒª

```bash
pip install langgraph langchain-anthropic anthropic
pip install chromadb sentence-transformers
pip install requests beautifulsoup4
pip install pillow
```

### é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [01-claude-design-philosophy.md](./01-claude-design-philosophy.md) - è¨­è¨ˆæ€æƒ³
- [02-context-engineering.md](./02-context-engineering.md) - Context Engineering
- [03-agent-architecture.md](./03-agent-architecture.md) - ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- [04-implementation-guide.md](./04-implementation-guide.md) - å®Ÿè£…ã‚¬ã‚¤ãƒ‰
- [05-multimodal-implementation.md](./05-multimodal-implementation.md) - ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«

---

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **æœ€å°é™ã®ä¾‹ã‹ã‚‰å§‹ã‚ã‚‹**: `minimal_agent.py` ã‚’å®Ÿè¡Œ
2. **ãƒ„ãƒ¼ãƒ«ã‚’è¿½åŠ **: `tool_agent.py` ã§ãƒ„ãƒ¼ãƒ«çµ±åˆã‚’å­¦ã¶
3. **RAGã‚’çµ±åˆ**: `rag_agent.py` ã§çŸ¥è­˜ãƒ™ãƒ¼ã‚¹çµ±åˆ
4. **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º**: ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ã£ã¦ç‹¬è‡ªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ

---

ã“ã‚Œã§ã€Claudeé¢¨ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã®å®Œå…¨ãªã‚¬ã‚¤ãƒ‰ãŒå®Œæˆã—ã¾ã—ãŸï¼
